{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Kernel Author:</b>  <br>\n",
    "<a href=\"https://bhishanpdl.github.io/\" , target=\"_blank\">Bhishan Poudel,  Data Scientist, Ph.D Astrophysics</a> .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This project uses the [consumer complaint database](https://catalog.data.gov/dataset/consumer-complaint-database).\n",
    "\n",
    "## Data Description\n",
    "The Consumer Complaint Database is a collection of complaints about consumer financial products and services that we sent to companies for response. Complaints are published after the company responds, confirming a commercial relationship with the consumer, or after 15 days, whichever comes first. Complaints referred to other regulators, such as complaints about depository institutions with less than $10 billion in assets, are not published in the Consumer Complaint Database. The database generally updates daily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Business Problem:</b>  <br>\n",
    "Task &nbsp;&nbsp; : Find the category of given complaint. <br>\n",
    "Metric : IF-IDF <br>\n",
    "Cleaning: Remove punctuations, expand contractions, etc <br>\n",
    "Question: Which class the given complaint belongs to?\n",
    "</div>\n",
    "\n",
    "oad the serialized object make sure you have the \n",
    "same conda environment as it was when creating the serialized object.\n",
    "</div>\n",
    "\n",
    "\n",
    "**Term Frequency** : This gives how often a given word appears within a document.\n",
    "\n",
    "$\\mathrm{TF}=\\frac{\\text { Number of times the term appears in the doc }}{\\text { Total number of words in the doc }}$\n",
    "\n",
    "**Inverse Document Frequency**: This gives how often the word appers across the documents.\n",
    "If a term is very common among documents (e.g., “the”, “a”, “is”),\n",
    "then we have low IDF score.\n",
    "\n",
    "$\\mathrm{IDF}=\\ln \\left(\\frac{\\text { Number of docs }}{\\text { Number docs the term appears in }}\\right)$\n",
    "\n",
    "**Term Frequency – Inverse Document Frequency TF-IDF**: \n",
    "TF-IDF is the product of the TF and IDF scores of the term.\n",
    "\n",
    "$\\mathrm{TF}-\\mathrm{IDF}=\\frac{\\mathrm{TF}}{\\mathrm{IDF}}$\n",
    "\n",
    "\n",
    "In machine learning, TF-IDF is obtained from the class `TfidfVectorizer`.\n",
    "It has following parameters:\n",
    "\n",
    "- `min_df`: remove the words from the vocabulary which have occurred in less than \"min_df\"\n",
    "number of files.\n",
    "- `max_df`: remove the words from the vocabulary which have occurred in more than _{ maxdf\" }\n",
    "total number of files in corpus.\n",
    "- `sublinear_tf`: set to True to scale the term frequency in logarithmic scale.\n",
    "- `stop_words`: remove the predefined stop words in 'english':\n",
    "- `use_idf`: weight factor must use inverse document frequency.\n",
    "- `ngram_range`: (1,2) to indicate that unigrams and bigrams will be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'config' has no attribute 'N_SAMPLES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-f85df68dbbcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_linsvc_tfidf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_linsvc_tfidf_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtfidf_fitted_vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf_fitted_vec_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mN_SAMPLES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'config' has no attribute 'N_SAMPLES'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start_notebook = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local scripts\n",
    "import util\n",
    "import config\n",
    "\n",
    "ifile = config.clean_data_path\n",
    "SEED = config.SEED\n",
    "model_linsvc_tfidf_path = config.model_linsvc_tfidf_path\n",
    "tfidf_fitted_vec_path = config.tfidf_fitted_vec_path\n",
    "N_SAMPLES = config.N_SAMPLES\n",
    "\n",
    "compression= config.compression\n",
    "\n",
    "# settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot') \n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "#Visualizers\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "\n",
    "# versions\n",
    "import watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Bhishan Poudel\" -d -v -m\n",
    "print()\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_methods(obj, ncols=4):\n",
    "    lst = [i for i in dir(obj) if i[0]!='_' ]\n",
    "    df = pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaints_2019.csv.zip       complaints_2019_clean.csv.zip orig_data_head_tail.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>complaint</th>\n",
       "      <th>complaint_lst_clean</th>\n",
       "      <th>complaint_clean</th>\n",
       "      <th>total_length</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82392</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>On XX/XX/2019 I sent a dispute letter to Fed Loan Servicing about the student loans they claim I owe. I asked them to send me verifiable information for the accounts and the information that they ...</td>\n",
       "      <td>['sent', 'dispute', 'letter', 'fed', 'loan', 'servicing', 'student', 'loan', 'claim', 'owe', 'asked', 'send', 'verifiable', 'information', 'account', 'information', 'sent', 'constitute', 'sent', '...</td>\n",
       "      <td>sent dispute letter fed loan servicing student loan claim owe asked send verifiable information account information sent constitute sent promissory note school lot information redacted supposed do...</td>\n",
       "      <td>970</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>4.645349</td>\n",
       "      <td>0.563953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "      <td>Someone applied for a vehicle in my name and now it is reflecting on my credit report and this is not my account</td>\n",
       "      <td>['someone', 'applied', 'vehicle', 'name', 'reflecting', 'credit', 'report', 'account']</td>\n",
       "      <td>someone applied vehicle name reflecting credit report account</td>\n",
       "      <td>112</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3.913043</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "      <td>My exwife opened a XXXX Credit card in 2009 ( 3 years before we ever met ). Shortly after we met, she added me as an authorized user and I never even had a card. The three credit reporting agencie...</td>\n",
       "      <td>['exwife', 'opened', 'credit', 'card', 'year', 'ever', 'met', 'shortly', 'met', 'added', 'authorized', 'user', 'never', 'even', 'card', 'three', 'credit', 'reporting', 'agency', 'claiming', 'joint...</td>\n",
       "      <td>exwife opened credit card year ever met shortly met added authorized user never even card three credit reporting agency claiming jointly owned account filed bankruptcy im responsible debt card nev...</td>\n",
       "      <td>601</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>4.145299</td>\n",
       "      <td>0.675214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61809</th>\n",
       "      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "      <td>AFTER RECEIVING A CURRENT COPY OF MY CREDIT REPORT, I DISCOVERED SOME ENTRIES THAT WERE IDENITIFIED AS INQUIRIES WHICH QUALIFIED FOR DELETION FROM MY REPORT.</td>\n",
       "      <td>['receiving', 'current', 'copy', 'credit', 'report', 'discovered', 'entry', 'idenitified', 'inquiry', 'qualified', 'deletion', 'report']</td>\n",
       "      <td>receiving current copy credit report discovered entry idenitified inquiry qualified deletion report</td>\n",
       "      <td>157</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            product  \\\n",
       "82392                                                                  Student loan   \n",
       "1435   Credit reporting, credit repair services, or other personal consumer reports   \n",
       "13448  Credit reporting, credit repair services, or other personal consumer reports   \n",
       "61809  Credit reporting, credit repair services, or other personal consumer reports   \n",
       "\n",
       "                                                                                                                                                                                                     complaint  \\\n",
       "82392  On XX/XX/2019 I sent a dispute letter to Fed Loan Servicing about the student loans they claim I owe. I asked them to send me verifiable information for the accounts and the information that they ...   \n",
       "1435                                                                                          Someone applied for a vehicle in my name and now it is reflecting on my credit report and this is not my account   \n",
       "13448  My exwife opened a XXXX Credit card in 2009 ( 3 years before we ever met ). Shortly after we met, she added me as an authorized user and I never even had a card. The three credit reporting agencie...   \n",
       "61809                                            AFTER RECEIVING A CURRENT COPY OF MY CREDIT REPORT, I DISCOVERED SOME ENTRIES THAT WERE IDENITIFIED AS INQUIRIES WHICH QUALIFIED FOR DELETION FROM MY REPORT.   \n",
       "\n",
       "                                                                                                                                                                                           complaint_lst_clean  \\\n",
       "82392  ['sent', 'dispute', 'letter', 'fed', 'loan', 'servicing', 'student', 'loan', 'claim', 'owe', 'asked', 'send', 'verifiable', 'information', 'account', 'information', 'sent', 'constitute', 'sent', '...   \n",
       "1435                                                                                                                    ['someone', 'applied', 'vehicle', 'name', 'reflecting', 'credit', 'report', 'account']   \n",
       "13448  ['exwife', 'opened', 'credit', 'card', 'year', 'ever', 'met', 'shortly', 'met', 'added', 'authorized', 'user', 'never', 'even', 'card', 'three', 'credit', 'reporting', 'agency', 'claiming', 'joint...   \n",
       "61809                                                                 ['receiving', 'current', 'copy', 'credit', 'report', 'discovered', 'entry', 'idenitified', 'inquiry', 'qualified', 'deletion', 'report']   \n",
       "\n",
       "                                                                                                                                                                                               complaint_clean  \\\n",
       "82392  sent dispute letter fed loan servicing student loan claim owe asked send verifiable information account information sent constitute sent promissory note school lot information redacted supposed do...   \n",
       "1435                                                                                                                                             someone applied vehicle name reflecting credit report account   \n",
       "13448  exwife opened credit card year ever met shortly met added authorized user never even card three credit reporting agency claiming jointly owned account filed bankruptcy im responsible debt card nev...   \n",
       "61809                                                                                                      receiving current copy credit report discovered entry idenitified inquiry qualified deletion report   \n",
       "\n",
       "       total_length  num_words  num_sent  num_unique_words  avg_word_len  \\\n",
       "82392           970        172         1                97      4.645349   \n",
       "1435            112         23         1                19      3.913043   \n",
       "13448           601        117         1                79      4.145299   \n",
       "61809           157         25         1                24      5.320000   \n",
       "\n",
       "       avg_unique  \n",
       "82392    0.563953  \n",
       "1435     0.826087  \n",
       "13448    0.675214  \n",
       "61809    0.960000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/complaints_2019_clean.csv.zip',compression='zip')\n",
    "\n",
    "# make data small\n",
    "df = df.sample(n=N_SAMPLES, random_state=SEED)\n",
    "df.head(2).append(df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "maincol = 'complaint'\n",
    "mc = maincol + '_clean'\n",
    "target = 'product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_orig'] = df['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product'] = df['product'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.59 ms, sys: 1.02 ms, total: 3.61 ms\n",
      "Wall time: 3.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['complaint_clean'] # documents\n",
    "y = df['product'].astype('category').cat.codes # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=config.train_size,\n",
    "                                                    random_state=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8], [0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(y_train.unique()), sorted(y_test.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling: LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "RE_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RE_TRAIN:\n",
    "    tfidf = TfidfVectorizer(**config.params_tfidf)\n",
    "\n",
    "    fitted_vectorizer = tfidf.fit(X_train)\n",
    "    tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n",
    "\n",
    "    model = svm.LinearSVC(**config.params_linsvc)\n",
    "    model.fit(tfidf_vectorizer_vectors, y_train)\n",
    "    joblib.dump(model, model_linsvc_tfidf_path )\n",
    "    joblib.dump(fitted_vectorizer, tfidf_fitted_vec_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy              : 0.8125 \n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(model_linsvc_tfidf_path)\n",
    "fitted_vectorizer = joblib.load(tfidf_fitted_vec_path)\n",
    "\n",
    "X_train_text = fitted_vectorizer.transform(X_train)\n",
    "X_test_text  = fitted_vectorizer.transform(X_test)\n",
    "\n",
    "ypreds = model.predict(X_test_text)\n",
    "print('Accuracy              : {:.4f} '.format(metrics.accuracy_score(y_test,ypreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>fit</td>\n",
       "      <td>max_iter</td>\n",
       "      <td>random_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>fit_intercept</td>\n",
       "      <td>multi_class</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classes_</td>\n",
       "      <td>get_params</td>\n",
       "      <td>n_features_in_</td>\n",
       "      <td>set_params</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coef_</td>\n",
       "      <td>intercept_</td>\n",
       "      <td>n_iter_</td>\n",
       "      <td>sparsify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_function</td>\n",
       "      <td>intercept_scaling</td>\n",
       "      <td>penalty</td>\n",
       "      <td>tol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>densify</td>\n",
       "      <td>loss</td>\n",
       "      <td>predict</td>\n",
       "      <td>verbose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dual</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                  1               2             3\n",
       "0                  C                fit        max_iter  random_state\n",
       "1       class_weight      fit_intercept     multi_class         score\n",
       "2           classes_         get_params  n_features_in_    set_params\n",
       "3              coef_         intercept_         n_iter_      sparsify\n",
       "4  decision_function  intercept_scaling         penalty           tol\n",
       "5            densify               loss         predict       verbose\n",
       "6               dual                                                 "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03393898e-03, 1.11447689e-02, 9.46803176e-01, 2.29536627e-02,\n",
       "        2.25909015e-03, 1.79027402e-03, 2.61764108e-03, 3.52172169e-03,\n",
       "        7.87572657e-03],\n",
       "       [2.27591259e-01, 6.79365421e-01, 4.45497356e-02, 1.20384988e-02,\n",
       "        9.34615172e-03, 9.83929076e-03, 4.75855963e-03, 3.37268296e-03,\n",
       "        9.13840023e-03],\n",
       "       [1.45642463e-02, 1.28215433e-02, 8.28846294e-01, 1.16644359e-01,\n",
       "        1.83326199e-03, 7.39376921e-03, 3.35941513e-03, 8.27152674e-03,\n",
       "        6.26558447e-03],\n",
       "       [4.20867212e-03, 4.96180288e-01, 4.43500619e-01, 3.69750322e-02,\n",
       "        1.94862440e-03, 1.84292341e-03, 4.79874448e-03, 7.81116049e-04,\n",
       "        9.76398018e-03],\n",
       "       [5.56716064e-03, 3.22849516e-03, 9.78089421e-02, 7.99976820e-01,\n",
       "        4.24207748e-03, 1.04630991e-02, 3.56641015e-02, 9.17440176e-03,\n",
       "        3.38749025e-02]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear svm does not have probs, we need to use calibrated classifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf = CalibratedClassifierCV(model) \n",
    "clf.fit(X_train_text, y_train)\n",
    "\n",
    "yprobs = clf.predict_proba(X_test_text)\n",
    "yprobs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../outputs/ytest.csv',y_test,fmt='%d')\n",
    "np.savetxt('../outputs/ypreds_linsvc.csv',ypreds,fmt='%d')\n",
    "np.savetxt('../outputs/yprobs_linsvc.csv',yprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ytest</th>\n",
       "      <th>ypreds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58324</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96981</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29952</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70705</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109585</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ytest  ypreds\n",
       "58324       2       2\n",
       "96981       1       1\n",
       "29952       2       2\n",
       "70705       2       2\n",
       "109585      3       3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.DataFrame({'ytest': y_test, 'ypreds': ypreds})\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ytest</th>\n",
       "      <th>ypreds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72777</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112179</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50082</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52608</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16212</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ytest  ypreds\n",
       "72777       2       3\n",
       "112179      2       1\n",
       "50082       2       1\n",
       "52608       2       3\n",
       "16212       3       2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.query(\"ytest != ypreds\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mis-classified Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_id_to_product = dict(enumerate(df['product'].unique()))\n",
    "dic_product_to_id = {v:k for k,v in dic_id_to_product.items()}\n",
    "\n",
    "ser_id_to_product = pd.Series(dic_id_to_product)\n",
    "ser_product_to_id = pd.Series(dic_product_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Debt collection' predicted as 'Mortgage' : 21 examples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23968</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>XXXX XXXX XXXX believes I owe them {$7800.00} for terminating a lease in 2015. I gave them more than enough notice that I would have to leave the apartment due t the lack of affordability because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23699</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>In response to a denial of an extension of credit this consumer checked with the consumer reporting agencies and found the following : 1. Your company has furnished negative information about this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11400</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I was Evicted from my home in XX/XX/2017 I paid all my debt from the landlord and then a year later the name Hunter Warfield showed on my credit report. I was never given a notice about this charg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39758</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I've lived in P.R all my life, never in the U.S. Since XX/XX/2017 I have received collection notifications from different creditors of the U.S. I already reported to the P.R. Police Department, at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89226</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>This letter is to inform you that Lending Club has failed to respond to my credit dispute letter and failed to verify that this account belongs to me that I sent certified mail on XX/XX/2019. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51947</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>On XX/XX/2018 I have contacted a agency called Credit Collection Services and XXXX XXXX XXXX advising them that I discovered a account that has been opened as a result of fraud. This agency failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30341</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I am a single mother. I recently tried to purchase a home for my family and was denied. I than reviewed my own credit report and seen a lot of unauthorized credit inquires on my credit report that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14577</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I have called this company and told them this is not my account, they continue to refuse to accept it. I asked for proof to be provided, they sent me a letter with an address that I do not recogni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>FCO has reported a collection on my credit report this year. I had no idea that I had a collection because I pay all my bills on time. I reached out to FCO who collected all my personal info, conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25393</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>The following Hard inquiries were made on my credit : XXXX XXXX XXXX XX/XX/XXXX XXXX XXXX XXXX XXXX XX/XX/2018 XXXX XXXX XXXX XXXX XX/XX/XXXX XXXX XXXX XXXX XX/XX/XXXX In XX/XX/2018, I Applied cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90015</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I recently reviewed my XXXX credit report and I was totally shocked to find Capital One Bank is still reporting these fraudulent accounts on my credit report. I am requesting for Capital One Bank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58634</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I received several emails from Bank of America about settling an outstanding debt for {$42.00}. I reached out to the company on XX/XX/2019. I spoke to a collection agent regarding the email and sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57907</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>KINGS CREDIT SERVICE XXXX XXXX XXXX XXXX XXXX, CA XXXX ( XXXX ) XXXX Kings Credit Service Opened XX/XX/2018 {$46.00} Original creditor : XXXX XXXX XXXX XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80607</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I applied to rent an apartment at XXXX in XXXX XXXX while it was still under construction in XXXX of 2019. My application was denied and I never moved in. A few months later I noticed that I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85527</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>NOTICE OF PENDING LITIGATION SEEKING RELIEF AND MONETARY DAMAGES UNDER FCRA SECTION 616 &amp; SECTION 617/// TRIDENT ASST MANAG IS REPORTING AN ACCOUNT ON MY CREDIT THAT IS NOT MINE/INACCURATE.FRAUD. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42457</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>SOUTHERN MANAGEMENT SYSTEMS IS REPORTING FALSE INFORMATION ON MY CREDIT REPORT! REMOVE ALL NEGATIVE ITEMS ON CREDIT REPORT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I was an XXXX customer. I had a complaint filed with the XXXX for unfair sales practices and fraud. ( they added services specifically XXXX  XXXX/XXXX XXXX  that I did not request. They also chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27520</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Again this XXXX XXXX XXXX has sent nothing other than a generic letter. They responded to your company saying it will be removed soon but nothing explaining when and this is past the statue of lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>The Mini Van was reported stolen to the Police but resolved that it was retrieve by XXXX XXXX as repossess without notice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99224</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Transworld apparently purchased an account from XXXX or took over an account from XXXX  for which I had an open dispute, they have reported it to credit reporting agencies negatively impacting my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13818</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>XXXX XXXX XXXX XXXX XXXX XXXX XXXX, GA XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX, XXXX  XXXX XXXX # XXXX To Whom It May Concern : This letter is being sent to you in response to notic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               product  \\\n",
       "23968  Debt collection   \n",
       "23699  Debt collection   \n",
       "11400  Debt collection   \n",
       "39758  Debt collection   \n",
       "89226  Debt collection   \n",
       "51947  Debt collection   \n",
       "30341  Debt collection   \n",
       "14577  Debt collection   \n",
       "13315  Debt collection   \n",
       "25393  Debt collection   \n",
       "90015  Debt collection   \n",
       "58634  Debt collection   \n",
       "57907  Debt collection   \n",
       "80607  Debt collection   \n",
       "85527  Debt collection   \n",
       "42457  Debt collection   \n",
       "8244   Debt collection   \n",
       "27520  Debt collection   \n",
       "5846   Debt collection   \n",
       "99224  Debt collection   \n",
       "13818  Debt collection   \n",
       "\n",
       "                                                                                                                                                                                                     complaint  \n",
       "23968  XXXX XXXX XXXX believes I owe them {$7800.00} for terminating a lease in 2015. I gave them more than enough notice that I would have to leave the apartment due t the lack of affordability because ...  \n",
       "23699  In response to a denial of an extension of credit this consumer checked with the consumer reporting agencies and found the following : 1. Your company has furnished negative information about this...  \n",
       "11400  I was Evicted from my home in XX/XX/2017 I paid all my debt from the landlord and then a year later the name Hunter Warfield showed on my credit report. I was never given a notice about this charg...  \n",
       "39758  I've lived in P.R all my life, never in the U.S. Since XX/XX/2017 I have received collection notifications from different creditors of the U.S. I already reported to the P.R. Police Department, at...  \n",
       "89226  This letter is to inform you that Lending Club has failed to respond to my credit dispute letter and failed to verify that this account belongs to me that I sent certified mail on XX/XX/2019. This...  \n",
       "51947  On XX/XX/2018 I have contacted a agency called Credit Collection Services and XXXX XXXX XXXX advising them that I discovered a account that has been opened as a result of fraud. This agency failed...  \n",
       "30341  I am a single mother. I recently tried to purchase a home for my family and was denied. I than reviewed my own credit report and seen a lot of unauthorized credit inquires on my credit report that...  \n",
       "14577  I have called this company and told them this is not my account, they continue to refuse to accept it. I asked for proof to be provided, they sent me a letter with an address that I do not recogni...  \n",
       "13315  FCO has reported a collection on my credit report this year. I had no idea that I had a collection because I pay all my bills on time. I reached out to FCO who collected all my personal info, conf...  \n",
       "25393  The following Hard inquiries were made on my credit : XXXX XXXX XXXX XX/XX/XXXX XXXX XXXX XXXX XXXX XX/XX/2018 XXXX XXXX XXXX XXXX XX/XX/XXXX XXXX XXXX XXXX XX/XX/XXXX In XX/XX/2018, I Applied cre...  \n",
       "90015  I recently reviewed my XXXX credit report and I was totally shocked to find Capital One Bank is still reporting these fraudulent accounts on my credit report. I am requesting for Capital One Bank ...  \n",
       "58634  I received several emails from Bank of America about settling an outstanding debt for {$42.00}. I reached out to the company on XX/XX/2019. I spoke to a collection agent regarding the email and sh...  \n",
       "57907                                             KINGS CREDIT SERVICE XXXX XXXX XXXX XXXX XXXX, CA XXXX ( XXXX ) XXXX Kings Credit Service Opened XX/XX/2018 {$46.00} Original creditor : XXXX XXXX XXXX XXXX  \n",
       "80607  I applied to rent an apartment at XXXX in XXXX XXXX while it was still under construction in XXXX of 2019. My application was denied and I never moved in. A few months later I noticed that I had a...  \n",
       "85527  NOTICE OF PENDING LITIGATION SEEKING RELIEF AND MONETARY DAMAGES UNDER FCRA SECTION 616 & SECTION 617/// TRIDENT ASST MANAG IS REPORTING AN ACCOUNT ON MY CREDIT THAT IS NOT MINE/INACCURATE.FRAUD. ...  \n",
       "42457                                                                              SOUTHERN MANAGEMENT SYSTEMS IS REPORTING FALSE INFORMATION ON MY CREDIT REPORT! REMOVE ALL NEGATIVE ITEMS ON CREDIT REPORT.  \n",
       "8244   I was an XXXX customer. I had a complaint filed with the XXXX for unfair sales practices and fraud. ( they added services specifically XXXX  XXXX/XXXX XXXX  that I did not request. They also chang...  \n",
       "27520  Again this XXXX XXXX XXXX has sent nothing other than a generic letter. They responded to your company saying it will be removed soon but nothing explaining when and this is past the statue of lim...  \n",
       "5846                                                                                The Mini Van was reported stolen to the Police but resolved that it was retrieve by XXXX XXXX as repossess without notice.  \n",
       "99224  Transworld apparently purchased an account from XXXX or took over an account from XXXX  for which I had an open dispute, they have reported it to credit reporting agencies negatively impacting my ...  \n",
       "13818  XXXX XXXX XXXX XXXX XXXX XXXX XXXX, GA XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX, XXXX  XXXX XXXX # XXXX To Whom It May Concern : This letter is being sent to you in response to notic...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for predicted in ser_id_to_product.index:\n",
    "    for actual in ser_id_to_product.index:\n",
    "        if predicted != actual and conf_mat[actual, predicted] >= 20:\n",
    "            print(\"'{}' predicted as '{}' : {} examples.\".format(dic_id_to_product[actual], \n",
    "                                                               dic_id_to_product[predicted], \n",
    "                                                               conf_mat[actual, predicted]))\n",
    "            # indices_test is from train-test split\n",
    "            display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['product', \n",
    "                                                                    'complaint']])\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most correlated terms with each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "#                         ngram_range=(1, 2), \n",
    "#                         stop_words='english')\n",
    "\n",
    "# # create vectors\n",
    "# features = tfidf.fit_transform(df['complaint_clean']).toarray()\n",
    "# labels = df['category_id']\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9c\" ><caption>Top Correlated Terms per Category</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >product</th>        <th class=\"col_heading level0 col1\" >unigram</th>        <th class=\"col_heading level0 col2\" >bigram</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow0_col0\" class=\"data row0 col0\" >Student loan</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow0_col1\" class=\"data row0 col1\" >branch, bank, deposit, overdraft</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow0_col2\" class=\"data row0 col2\" >saving account, called bank, checking account, card payment</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow1_col0\" class=\"data row1 col0\" >Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow1_col1\" class=\"data row1 col1\" >card, capital, express, statement</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow1_col2\" class=\"data row1 col2\" >credit card, american express, card account, fraudulent charge</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow2_col0\" class=\"data row2 col0\" >Mortgage</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow2_col1\" class=\"data row2 col1\" >experian, report, equifax, reporting</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow2_col2\" class=\"data row2 col2\" >credit bureau, xxxx reporting, fraud alert, victim identity</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow3_col0\" class=\"data row3 col0\" >Debt collection</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow3_col1\" class=\"data row3 col1\" >debt, collection, calling, phone</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow3_col2\" class=\"data row3 col2\" >account credit, certified mail, time day, funding llc</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow4_col0\" class=\"data row4 col0\" >Money transfer, virtual currency, or money service</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow4_col1\" class=\"data row4 col1\" >paypal, transfer, ticket, transaction</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow4_col2\" class=\"data row4 col2\" >money order, money account, transfer fund, account said</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow5_col0\" class=\"data row5 col0\" >Vehicle loan or lease</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow5_col1\" class=\"data row5 col1\" >mortgage, escrow, home, foreclosure</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow5_col2\" class=\"data row5 col2\" >loan modification, escrow account, short sale, loan officer</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow6_col0\" class=\"data row6 col0\" >Credit card or prepaid card</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow6_col1\" class=\"data row6 col1\" >loan, lending, title, lied</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow6_col2\" class=\"data row6 col2\" >received loan, loan told, called asked, loan agreement</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow7_col0\" class=\"data row7 col0\" >Checking or savings account</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow7_col1\" class=\"data row7 col1\" >navient, university, loan, owned</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow7_col2\" class=\"data row7 col2\" >loan forgiveness, fed loan, student loan, thank time</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow8_col0\" class=\"data row8 col0\" >Payday loan, title loan, or personal loan</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow8_col1\" class=\"data row8 col1\" >car, vehicle, leased, gm</td>\n",
       "                        <td id=\"T_4f87397e_1547_11eb_9f5c_8c859004fb9crow8_col2\" class=\"data row8 col2\" >gm financial, auto loan, fee payment, auto finance</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fab97ee9fd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_N_correlated(N=4,ser_id_to_product=ser_id_to_product):\n",
    "    products,top_uni,top_bi = [],[],[]\n",
    "    for category_id, product in ser_id_to_product.iteritems():\n",
    "        indices = np.argsort(model.coef_[category_id])\n",
    "        feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "        unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "        bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "        products.append(product)\n",
    "        top_uni.append(', '.join(unigrams[-N:]))\n",
    "        top_bi.append(', '.join(bigrams[-N:]))\n",
    "    # dataframe\n",
    "    df_top_corr = pd.DataFrame({'product': products,\n",
    "                                'unigram': top_uni,\n",
    "                                'bigram': top_bi})\n",
    "    \n",
    "    return df_top_corr\n",
    "\n",
    "df_top_corr = get_top_N_correlated(N=4)\n",
    "df_top_corr.style.set_caption('Top Correlated Terms per Category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['complaint_clean'] # documents\n",
    "y = df['product'].astype('category').cat.codes # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "\n",
    "fitted_vectorizer = tfidf.fit(X_train)\n",
    "tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n",
    "\n",
    "model = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/tfidf.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fitted model (model persistence)\n",
    "joblib.dump(model, '../models/tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_complaint = \"\"\"Hello : ditech.com is my mortgagecompany.\n",
    "They placed an automatic forbearance on my account\n",
    "and removed my auto payment after\n",
    "Hurricane Irma. \n",
    "I called about a week after the storm\n",
    "to ask that they remove the forbearance\n",
    "and return the auto payment.\n",
    "This was confirm by the agent\n",
    "and recorded by them. \n",
    "I received a letter just a few \n",
    "weeks ago stating that my auto payment\n",
    "was never returned and the agent who\n",
    "I spoke with after I received the\n",
    "letter actually read back the notes\n",
    "confirming that I called and asked \n",
    "to have forbearance removed and auto\n",
    "payment reinstated.\n",
    "So I asked again the agent \n",
    "to remove the forbearance and install auto payment.\n",
    "\\n\\nI called this past week to check \n",
    "if this was done yet, and the agent\n",
    "at that time said I still have \n",
    "a forbearance and no auto payment.\n",
    "\\n\\nAs I right this complaint,\n",
    "I spoke with an agent today that\n",
    "informs me that I dont have auto \n",
    "payment and forbearance is still active.\n",
    "She placed me on hold, which has lasted an hour.\n",
    "\\n\\nDitech is not responsive,\n",
    "and it is purposely choosing \n",
    "to keep my in forbearance when\n",
    "I have asked countless times to remove me.\n",
    "I also have asked countless times \n",
    "to reinstate auto payment and yet \n",
    "they choose not to listen.\n",
    "\\n\\nPlease help XXXX XXXX, XXXX\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "model_loaded = joblib.load('../models/tfidf.pkl')\n",
    "new_comp_vec = fitted_vectorizer.transform([new_complaint])\n",
    "pred = model_loaded.predict(new_comp_vec)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Time Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run whole notebook: 0 hr 7 min 10 secs\n"
     ]
    }
   ],
   "source": [
    "time_taken = time.time() - time_start_notebook\n",
    "h,m = divmod(time_taken,60*60)\n",
    "print('Time taken to run whole notebook: {:.0f} hr '\\\n",
    "      '{:.0f} min {:.0f} secs'.format(h, *divmod(m,60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataSc)",
   "language": "python",
   "name": "datasc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
